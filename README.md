# AORUS MASTER 16 AM6H 規格問答助理

針對 **GIGABYTE AORUS MASTER 16 AM6H** 系列筆電規格設計的本地端 RAG 問答系統。可針對特定型號進行規格查詢，也可針對不同型號進行比較。

---

## 1. 啟動步驟

### 環境安裝

```powershell
# 安裝 uv 套件管理器
pip install uv

# 安裝專案依賴
uv sync

# 確認安裝 llama.cpp 最新版本(由於硬體與支援問題，暫時使用 cpu 版本)
uv pip install llama-cpp-python==0.3.16 --force-reinstall --no-cache-dir
```

### 執行程式 (單一問答)

```powershell
python main.py
```

### 整批問答測試

```powershell
python batch_test.py
```

---

## 2. 生成模型選擇與對話參數

### 2.1 Embedding Model : 
#### Qwen3-Embedding-0.6B-Q8_0
- Qwen 系列最新 Embedding Model
- 針對中文表現力較佳、能更好處理中英文間的語意
- 大小適中，在效能與記憶體間取得平衡

### 2.2 LLM : 
#### Qwen3-4b-it-Q4_K_M

- 中文表現優異，較不會出現語言不一致的狀況
- 選擇 **unsloth 優化版本**，記憶體使用更佳、推論速度經過優化
- 量化格式選擇 **Q4_K_M**，在速度、記憶與能力上取得較好平衡
- 評測結果顯示，在除了生成速度略低於 Gemma 3 4B 之外，其餘表現皆優於 Gemma 3 4B

### 2.3 對話預算參數選擇
- context_size : 4096
- max_tokens : 512
- kv_cache 量化 : q8_0

## 3. 架構圖

### 3.1 資料解析

**資料檔案：**
- `AORUS MASTER 16 AM6H.html` - 原始網頁 HTML（產品規格頁面）
- `data/raw_specs.json` - HTML 解析後的原始規格 JSON
- `data_processing/knowledge_base/specs_integrated.json` - 整合後的產品規格 JSON（主要資料來源）

**解析流程：**
```
AORUS MASTER 16 AM6H.html
        │
        ▼
┌─────────────────────────────────────────┐
│ parse_html.py                           │
│ BeautifulSoup 解析 HTML 整合成 json 表   │
└─────────────────────────────────────────┘
        │
        ▼
    raw_specs.json
        │
        ▼
┌─────────────────────────────────────────┐
│ build_kb.py                             │
│ 整合多產品規格、key mapper                │ 
└─────────────────────────────────────────┘
        │
        ▼
  data_processing/knowledge_base/specs_integrated.json
        │
        ▼
┌─────────────────────────────────────────┐
│ data_loader.py                          │
│ 轉換 JSON 為 Chunks                     │
└─────────────────────────────────────────┘
        │
        ├── 單一規格 Chunk ──────────────┐
        │   描述某產品的某規格            │
        │   與該部件的相關詞彙            │
        │                                │
        └── Full Specs Chunk ────────────┤
            描述某產品的整機規格           │
            用於比較模式                  │
                                         │
        ▼                                │
┌─────────────────────────────────────────┐
│ Embedding Index (retriever.py)          │
│ 向量化並建立索引                         │
└─────────────────────────────────────────┘
```
Chunk 範例 :
```
Product: AORUS MASTER 16 BYH
Category: Processor
Specification: OS
Value: Windows 11 Pro (GIGABYTE recommends Windows 11 Pro for business.)
Windows 11 Home
UEFI Shell OS
```

### 3.2 檢索與生成的流程

```
使用者問題
    │
    ▼
┌─────────────────────────────────────────┐
│ 1. 產品名稱提取 & 意圖分類                │
│    識別問題中的產品型號 (BXH/BYH/BZH)     │
│    偵測比較關鍵字 (比較/差別/difference)  │
└─────────────────────────────────────────┘
    │
    ├─────────────────┬─────────────────┐
    │                 │                 │
    ▼                 ▼                 ▼
┌───────────┐   ┌───────────┐   ┌───────────┐
│Comparison │   │  Common   │   │ Specific  │
│ (比較模式) │   │ (一般查詢) │   │ (特定產品) │
└───────────┘   └───────────┘   └───────────┘
    │                 │                 │
    ▼                 ▼                 ▼
┌───────────┐   ┌──────────────┐   ┌───────────────┐
│直接返回所有│   │ Hybrid Search│   │ Hybrid Search │
│產品的 Full│    │搜尋全部chunks│   │搜尋該產品chunks│
│Specs chunk│   └──────────────┘   └───────────────┘ 
│(跳過檢索) │          │                  │
└───────────┘         │                  │
    │                 │                  │
    │                 ├ ─ ─ ─ ─ ─ ─ ─ ─ ─┤
    │                 ▽                 ▽
    │           ┌ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ┐
    │           │ (選用) QA Dataset 檢索   │
    │           │ 可新增特定問答確保結果    │
    │           └ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ┘
    │                 │                 │
    └─────────────────┴─────────────────┘
                      │
                      ▼
┌─────────────────────────────────────────┐
│ 2. Context 組合                          │
│    ├─ 檢索結果 + 信心分數                 │
│    └─ (選用) QA 資料庫結果                │
└─────────────────────────────────────────┘
                      │
                      ▼
┌─────────────────────────────────────────┐
│ 3. LLM 生成                             │
│    ├─ System Prompt 限制回答範圍         │
│    ├─ 語言規則: 回答語言須與問題一致       │
│    └─ 串流生成回答                       │
└─────────────────────────────────────────┘
                      │
                      ▼
┌-----------------------------------------┐
│ 4. 後處理 (暫時沒加入)                   │
│    ├─ 移除信心分數洩漏                   │
│    └─ 統一 Fallback 回應格式             │
└-----------------------------------------┘
```
## 4. 評測結果分析


### 4.1 **測試資料** : test_questions.csv
- 內容包含 Specific、Common、Comparison、Irrelevant 四種類型問題，共 50 題。


### 4.2 **測試方法** : 
調整 RAG 參數與模型，測試對檢索與生成結果的影響。
- **model** : qwen3-4b、gemma-3-4b
- **Temperature** : 0.0, 0.3, 0.7
- **Top_k** : 3, 5

### 4.3 **評估項目** : 
**定量指標：**
- **檢索正確率** : 檢索到的 chunk 是否包含答案需要的全部資訊
- **TTFT** : 每一題答案的平均首字生成時間
- **TPS** : 每一題答案的平均生成速度

**定性分析：**

- **答案準確度** : 生成的答案是否正確、是否有不相關輸出及語言不一致
- **平均長度** : 每一題答案的平均長度
- **平均每題執行時間** : 每一題答案的平均生成時間 (礙於硬體支援，暫時使用 cpu 執行，CPU : AMD Ryzen 5 7500F)

**RAGAS 分析**
- **Faithfulness** : 回答是否有被檢索內容支持
- **Answer Relevancy** : 回答是否與問題相關

---
**gemma3-4b**
| Temp | Top_k |檢索正確率| TTFT(S)|TPS| 答案準確度 |平均長度|平均每題執行時間(S)|
| --- | --- | :---: | :---:  | :---: | :---: | :---: | :---: |
| 0.0 | 3 | 96% | 2.44 | 13.65| 94% | 73.7 | 5.46 
| 0.3 | 3 | 96% | 2.43 | 13.7| 92% | 76.4 | 5.61 
| 0.7 | 3 | 96% | 2.41 | 13.76| 88% | 71.4 | 5.38 
| 0.0 | 5 | 96% | 3.55 | 13.51| 90% | 73.1 | 6.59 
| 0.3 | 5 | 96% | 3.54 | 13.6| 90% | 76.2 | 6.63 
| 0.7 | 5 | 96% | 3.61 | 13.93| 90% | 71.5 | 6.53 

**qwen3-4b**
| Temp | Top_k |檢索正確率| TTFT(S)|TPS| 答案準確度 |平均長度|平均每題執行時間(S)|
| --- | --- | :---: | :---:  | :---: | :---: | :---: | :---: |
| 0.0 | 3 | 96% | 2.98 | 15.04| 94% | 68.9 | 6.30 
| 0.3 | 3 | 96% | 2.94 | 15.25| 92% | 68.8 | 6.27 
| 0.7 | 3 | 96% | 2.95 | 15.37| 96% | 64.3 | 5.96 
| 0.0 | 5 | 96% | 4.37 | 15.0| 96% | 68.0 | 7.68 
| 0.3 | 5 | 96% | 4.37 | 14.92| 96% | 68.1 | 7.68 
| 0.7 | 5 | 96% | 4.30 | 14.98| 96% | 66.6 | 7.58 


### 4.4 結論

#### 檢索表現
- **96% 檢索正確率**，證明 Hybrid Search 策略與 Query Filter 設計有效，但仍有些許改進空間，可以嘗試調整更多不同的 Hybrid Search 策略。
- Top_k 從 3 提升至 5 對檢索正確率沒有影響，甚至會降低答案準確度，表示前三名檢索結果已涵蓋所需資訊，可以選擇較小的 Top_k 即可。

#### TTFT 與 TPS
- 在相同檢索正確率與相近輸出長度下，
gemma3-4B 在 TTFT 上具有穩定優勢，適合即時互動型應用

- qwen3-4B 在 TPS 上表現更佳，適合長文本或高吞吐生成任務。
- Top-k 提升會顯著增加 TTFT，但對 TPS 幾乎沒有影響，顯示 檢索主要影響 prefill 階段而非生成階段。
- **Top_k 對 TTFT 影響顯著**：Top_k 從 3 增加到 5，TTFT 增加約 **45-50%**，在增加 Top_k 時需要考慮增加 TTFT 的時間成本。


#### 答案準確度
- **qwen3-4b** 表現穩定，準確度在 **94%-96%** 之間，暫無隨著 Temperature 升高而出現不穩定的情況，但為保守起見，可以選擇中間值 0.3 即可。
- **gemma3-4b** 準確度範圍較廣 (**88%-94%**)，在 Temperature=0.7 時下降至 88%，顯示對高隨機性較敏感。
- 評測結果證明 qwen3-4b 在答案準確度上表現較 gemma3-4b 穩定可靠。

#### 生成速度
- **gemma3-4b 較快**：平均每題 5.38-6.63 秒。
- **qwen3-4b 較慢**：平均每題 5.96-7.68 秒。
- gemma3-4b 生成速度約快 **10-15%**，適合對回應速度有要求的場景，但須注意參數設置，否則會降低準確度。

#### 回應長度
- gemma3-4b 平均回應長度（71-76 字）與 qwen3-4b （64-69 字）表現並未差異過大。
- 兩者皆未出現冗長回答問題，表示目前的 System Prompt 控制效果良好。

#### 最佳配置建議
| 使用場景 | 建議模型 | 建議參數 |
| --- | --- | --- |
| 追求準確度與穩定性 | qwen3-4b | Temp=0.3, Top_k=3 |
| 追求回應速度 | gemma3-4b | Temp=0.0, Top_k=3 |
| 平衡表現 | qwen3-4b | Temp=0.3, Top_k=3 |

#### RAGAS 分析
| Metric | Mean | STD |
| --- | --- | --- |
| Faithfulness | 0.8637 | 0.2994 |
| Answer Relevancy | 0.7824 | 0.1988 |

- Faithfulness 表現優異，平均得分為 0.86，顯示生成的回答確實根據檢索到的上下文內容，較少產生幻覺，但標準差略高，可能在處理較複雜的問題時，需要更精確的檢索內容。
- Answer Relevancy表現中上，平均得分為 0.78，且標準差僅 0.20，顯示系統在回答問題的切題性上相當穩定。雖然得分略低於Faithfulness，但仍能有效針對問題核心進行回應。
- 綜合兩個分數來看，模型確實有在用 context，但「用錯地方」或「答得不夠精準」的情況仍有進步空間。

註：Ragas 測試已排除 Irrelevant 問題共七題

---

## 5. 開發流程

|  | 2/3 | 2/4 | 2/5 | 2/6 | 2/7 | 2/8 | 2/9 |
| --- | :---: | :---: | :---: | :---: | :---: | :---: | :---: |
| 資料格式、查詢方式構想 | ● |  |  |  |  |  |  |
| 檢索流程設計 |  | ● | ● |  |  |  |  |
| 生成模型挑選與流程設計 |  |  | ● | ● |  |  |  |
| 檢索過程改進 |  |  |  |  | ● | ● |  |
| 模型與參數評測 |  |  |  |  |  | ● | ● |
| Code Review |  |  |  |  |  |  | ● |


